{
  "last_node_id": 50,
  "last_link_id": 49,
  "nodes": [
    {
      "id": 15,
      "type": "EmptyLatentImage",
      "pos": [
        550,
        670
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [],
          "slot_index": 0,
          "label": "LATENT"
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        832,
        1216,
        1
      ]
    },
    {
      "id": 24,
      "type": "Reroute",
      "pos": [
        430,
        -40
      ],
      "size": [
        82,
        26
      ],
      "flags": {},
      "order": 28,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 25,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            21
          ],
          "slot_index": 0,
          "label": "MODEL"
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 14,
      "type": "EmptyLatentImage",
      "pos": [
        560,
        510
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            28
          ],
          "slot_index": 0,
          "label": "LATENT"
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1216,
        832,
        1
      ]
    },
    {
      "id": 11,
      "type": "Reroute",
      "pos": [
        -360,
        810
      ],
      "size": [
        75,
        26
      ],
      "flags": {},
      "order": 22,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 30,
          "slot_index": 0,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            17
          ],
          "slot_index": 0,
          "label": "VAE"
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 25,
      "type": "Reroute",
      "pos": [
        730,
        -40
      ],
      "size": [
        82,
        26
      ],
      "flags": {},
      "order": 31,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 21,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            22,
            34
          ],
          "slot_index": 0,
          "label": "MODEL"
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 37,
      "type": "Reroute",
      "pos": [
        1580,
        0
      ],
      "size": [
        140.8000030517578,
        26
      ],
      "flags": {},
      "order": 32,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 36,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            38
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 38,
      "type": "Reroute",
      "pos": [
        1580,
        40
      ],
      "size": [
        140.8000030517578,
        26
      ],
      "flags": {},
      "order": 33,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 37,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            39
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 36,
      "type": "Reroute",
      "pos": [
        1590,
        -40
      ],
      "size": [
        82,
        26
      ],
      "flags": {},
      "order": 35,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 34,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            35
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 35,
      "type": "PreviewImage",
      "pos": [
        2790,
        70
      ],
      "size": [
        460,
        510
      ],
      "flags": {},
      "order": 42,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 42,
          "label": "images"
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 39,
      "type": "SaveImage",
      "pos": [
        2780,
        640
      ],
      "size": [
        210,
        270
      ],
      "flags": {},
      "order": 43,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 49,
          "label": "images"
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        920,
        510
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [],
          "slot_index": 0,
          "label": "LATENT"
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 31,
      "type": "LatentUpscaleBy",
      "pos": [
        1810,
        110
      ],
      "size": [
        315,
        82
      ],
      "flags": {},
      "order": 37,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 31
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            32
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "LatentUpscaleBy"
      },
      "widgets_values": [
        "nearest-exact",
        1.5
      ]
    },
    {
      "id": 13,
      "type": "Reroute",
      "pos": [
        1150,
        810
      ],
      "size": [
        75,
        26
      ],
      "flags": {},
      "order": 24,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 17,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            18,
            43
          ],
          "slot_index": 0,
          "label": "VAE"
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 43,
      "type": "Reroute",
      "pos": [
        2410,
        460
      ],
      "size": [
        75,
        26
      ],
      "flags": {},
      "order": 26,
      "mode": 0,
      "inputs": [
        {
          "name": "",
          "type": "*",
          "link": 43,
          "label": ""
        }
      ],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            44
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "showOutputText": true,
        "horizontal": false
      }
    },
    {
      "id": 27,
      "type": "LoraLoader",
      "pos": [
        90,
        100
      ],
      "size": [
        315,
        126
      ],
      "flags": {},
      "order": 27,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 23,
          "label": "model"
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 24,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            25
          ],
          "slot_index": 0,
          "shape": 3,
          "label": "MODEL"
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            26,
            27
          ],
          "slot_index": 1,
          "shape": 3,
          "label": "CLIP"
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "anime_ixl/genbaneko_v4_illustrious_uo_1024-000040.safetensors",
        1,
        1
      ]
    },
    {
      "id": 12,
      "type": "PreviewImage",
      "pos": [
        1310,
        490
      ],
      "size": [
        460,
        510
      ],
      "flags": {},
      "order": 38,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 16,
          "label": "images"
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 47,
      "type": "RescaleCFG",
      "pos": [
        -480,
        20
      ],
      "size": [
        210,
        60
      ],
      "flags": {},
      "order": 23,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 46
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            47
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "RescaleCFG"
      },
      "widgets_values": [
        0.6
      ]
    },
    {
      "id": 30,
      "type": "VAELoader",
      "pos": [
        -1110,
        400
      ],
      "size": [
        315,
        58
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [],
          "shape": 3,
          "label": "VAE"
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "sdxl_vae_fp16_fix.safetensors"
      ]
    },
    {
      "id": 46,
      "type": "ModelSamplingDiscrete",
      "pos": [
        -710,
        10
      ],
      "size": [
        210,
        82
      ],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 45
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            46
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingDiscrete"
      },
      "widgets_values": [
        "v_prediction",
        true
      ]
    },
    {
      "id": 32,
      "type": "KSampler",
      "pos": [
        2160,
        -30
      ],
      "size": [
        315,
        474
      ],
      "flags": {},
      "order": 40,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 35,
          "label": "model"
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 38,
          "label": "positive"
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 39,
          "label": "negative"
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 32,
          "slot_index": 3,
          "label": "latent_image"
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            40
          ],
          "slot_index": 0,
          "label": "LATENT"
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        1047910362535969,
        "randomize",
        13,
        5,
        "euler_ancestral",
        "normal",
        0.6
      ]
    },
    {
      "id": 45,
      "type": "Note",
      "pos": [
        -680,
        980
      ],
      "size": [
        1540,
        290
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "About vPred Models:\nvPred models utilize a technique called v-prediction, which prioritizes stability.\n\nThis technique is also used in Imagen Video:\nhttps://arxiv.org/abs/2202.00512\nIt gained attention when Novel AI V3 was confirmed to use it:\nhttps://arxiv.org/abs/2409.15997v1\nUsing vPred Models in ComfyUI:\nTo use models with v-prediction in ComfyUI, special nodes are required:\n\nModel Sampling Discrete:\nhttps://comfyui-wiki.com/comfyui-nodes/advanced/model/model-sampling-discrete\nRescale CFG:\nhttps://comfyui-wiki.com/comfyui-nodes/advanced/model/rescale-cfg\n‚ö†Ô∏è Important Note:\nnoobAI‚Äôs epsilon-pred is different from vPred and works fine with standard nodes.\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 28,
      "type": "Note",
      "pos": [
        -1220,
        220
      ],
      "size": [
        430,
        130
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "Illustrious has a built-in VAE, so no additional VAE is needed.\nHowever, if a derivative model of Illustrious states that \"VAE is required,\" select a VAE below and reconnect the red node accordingly."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 48,
      "type": "Note",
      "pos": [
        -680,
        1320
      ],
      "size": [
        1980,
        350
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "About Illustrious XL v0.1\nIllustrious XL v0.1 has excellent prompt responsiveness, understands characters well even without LoRA, and has rapidly gained derivative models in less than a month since its release.\n\nCurrent Key Features\nEasier Manga Generation:\n   „ÉªIf you don‚Äôt want manga-style output, add \"2koma, comic, 4koma\" to the negative prompt.\n   „ÉªIf you do want manga, emphasize those keywords.\n\nQuality Keywords Placement:\n   „ÉªWorks best when placed at the beginning of the prompt rather than at the end.\n   „ÉªThis trend is also observed in derivative models.\n\nText Elements Appear Easily:\n   „ÉªHandwritten text, sound effects, and speech bubbles can appear without LoRA.\n   „ÉªUse \"speech bubble, sound effect, moaning\" in prompts to enhance them.\n\nTrained on Danbooru 2023 Dataset:\n   „ÉªIf you understand Danbooru tags, you can control outputs effectively.\n   „ÉªCan generate recent characters without needing LoRA.\n\nWide Interpretation of Tags:\n   „ÉªEven simple tags produce diverse outputs, preventing repetitive images.\n\nStrong Artist Tag Influence:\n   „ÉªThe base Illustrious XL v0.1 applies artist tags very aggressively.\n\n‚ö†Ô∏è Handling Artist Tags in ComfyUI\nSince artist tags in Illustrious XL v0.1 are too strong, it's recommended to weaken them using A1111-style syntax:\n(tag_name:strength).\n\nUsing LoRA Efficiently in ComfyUI\nTo make LoRA behave like in A1111 (<lora_name:strength>), install \"comfyui-prompt-control\" and remove the default \"Load LoRA\" node for a cleaner setup.\nüîó ComfyUI Prompt Control:\nhttps://github.com/asagi4/comfyui-prompt-control\n\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 16,
      "type": "Note",
      "pos": [
        -1220,
        -210
      ],
      "size": [
        450,
        230
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "For ComfyUI Beginners\nBasic Workflow for Illustrious XL vPred Derivative Models\nWorks without any extensions\n\nCompatible only with models labeled as \"vPred\"\n\nTested Models:\n„ÉªnoobaiXLNAILX_vPredTestVersion\nhttps://civitai.com/models/833294?modelVersionId=962003\n„ÉªNoobAiIter_XL - vPred\nhttps://civitai.com/models/873533\n\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 29,
      "type": "Note",
      "pos": [
        -740,
        -310
      ],
      "size": [
        490,
        220
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "When using models labeled as vPred, enable this red-colored group.\n\n‚ö†Ô∏è Warning: If this is enabled for models not labeled as vPred, the output will remain noisy and unusable.\n\nHow to Toggle the Group Nodes:\n   „ÉªDisable (Bypass vPred Processing):\n      „ÉªRight-click on the group and select \"Bypass Group Nodes\".\n\n   „ÉªEnable (Activate vPred Processing):\n      „ÉªRight-click and select \"Set Group Nodes to Always\"."
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 17,
      "type": "Note",
      "pos": [
        -220,
        -90
      ],
      "size": [
        630,
        140
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "Using LoRA in ComfyUI:\n   „ÉªYou can attach multiple LoRAs.\n   „ÉªThe Illustrious XL LoRA is recommended, but LoRA will work to some extent even for models that are not \n     vPred.\n   „ÉªLoRAs designed for Pony or Animazine models may work to some extent, but don't expect full compatibility.\n\nBy default, LoRA is not applied (if the node turns purple, it means it is skipped).\nIf you want to apply a specific LoRA, right-click on the node and select \"ByPASS\" to activate it."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 10,
      "type": "LoraLoader",
      "pos": [
        -240,
        100
      ],
      "size": [
        315,
        126
      ],
      "flags": {},
      "order": 25,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 47,
          "label": "model"
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 11,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            23
          ],
          "slot_index": 0,
          "shape": 3,
          "label": "MODEL"
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            24
          ],
          "slot_index": 1,
          "shape": 3,
          "label": "CLIP"
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoader"
      },
      "widgets_values": [
        "style_xl/sdxl-flat.safetensors",
        1,
        1
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        430,
        240
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 30,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 27,
          "slot_index": 0,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            6,
            37
          ],
          "slot_index": 0,
          "label": "CONDITIONING"
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "worst quality, bad hands,bad quality,bad anatomy,jpeg artifacts,signature,scan,watermark,old,oldest",
        [
          false,
          true
        ]
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 20,
      "type": "Note",
      "pos": [
        30,
        300
      ],
      "size": [
        380,
        120
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "In ComfyUI, the CLIPTextEncode is used to convert text (such as prompts) into a format that the AI can understand.\n\nFor negative prompts, this method is generally sufficient."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 19,
      "type": "Note",
      "pos": [
        420,
        -280
      ],
      "size": [
        450,
        230
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "Basic Structure for Positive Prompts:\nmasterpiece, best quality, [1girl/1boy/1other/...], [Character Name], [Work Title], other relevant tags, [Artist Name]\n\nFor Illustrious, you don‚Äôt need to include special words like in Pony, as it performs decently without them. However, both the base and derivative models of Illustrious seem to give more stable results when quality tags like masterpiece and best quality are placed near the beginning of the prompt.\n\nWhile it's ideal to use extensions and fix templates for consistent results, this is just sticking to the basic structure for now."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 23,
      "type": "Note",
      "pos": [
        930,
        -190
      ],
      "size": [
        390,
        160
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "KSampler: The KSampler is where the AI actually generates the image.\n\nSettings for KSampler:\nSteps: Set to 30 or below.\nCFG (Classifier-Free Guidance): Set between 5 and 7.\nSampler: Use Euler ancestral (Euler a).\nScheduler: Normal is fine.\n\nFor vPred Models:\nYou can set CFG to a lower value, as it still provides good responsiveness even with a reduced setting."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1320,
        1050
      ],
      "size": [
        210,
        58
      ],
      "flags": {},
      "order": 39,
      "mode": 4,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 48,
          "label": "images"
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1310,
        390
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 36,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7,
          "label": "samples"
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 18,
          "label": "vae"
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            16,
            48
          ],
          "slot_index": 0,
          "label": "IMAGE"
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 22,
      "type": "Note",
      "pos": [
        1310,
        230
      ],
      "size": [
        410,
        100
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "The VAEDecode is used to convert the AI-generated image back into a readable format for humans.\n\nBy default, it is set to preview only. If you want to save the image, you need to connect it to the Save Image node instead. \n\n(Note of the translator: Connected the node to the \"Save Image\" node, and disabled it. If you want to save the image, now you just have to right click on the \"Save Image\" node and click \"Bypass\" to re-enable it. To disable, just click \"Bypass\" again)"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 40,
      "type": "Note",
      "pos": [
        1790,
        -400
      ],
      "size": [
        1350,
        210
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "This time, I‚Äôve also used HiresFix.\n\nIn this example with a simple prompt, you may not notice a significant difference, but Illustrious tends to see a noticeable drop in quality when the prompt becomes longer or when multiple LoRAs are added.\nIn such cases, applying HiresFix often improves the results, which is why it‚Äôs been included. (This tendency is also common with derivative models.)\n\nHow to Toggle HiresFix\n   „ÉªTo Disable HiresFix:\n      „ÉªRight-click on the HiresFix group and select \"Set Group Nodes to Never\".\n   „ÉªTo Enable HiresFix:\n      „ÉªRight-click on the HiresFix group and select \"Set Group Nodes to Always\"."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 44,
      "type": "Note",
      "pos": [
        1800,
        840
      ],
      "size": [
        1330,
        170
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "How Hires.Fix Works\nIn simple terms, Hires.Fix works by upscaling the generated image in some way and then having the AI refine it, improving the quality and resolving issues when increasing the resolution.\nIt‚Äôs essentially the same as performing an Image-to-Image operation with the same prompt/conditions, but after the initial generation, the image is stretched to the target resolution before being refined by the AI.\n\nMethod Used:\nIn this case, the simplest method was used: directly upscaling the Latent space and then regenerating it.\n\nOther Methods:\nThere are alternative approaches, such as:\n   „ÉªPassing the image through VAE (to convert it back into an image), then using an upscaling model (like Real-ESRGAN) to enlarge the image. Afterward, the image is returned to Latent space and refined by the AI again.\n     This method can sometimes yield different results depending on the tools used."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 42,
      "type": "Note",
      "pos": [
        1820,
        250
      ],
      "size": [
        320,
        170
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "Here, for simplicity, we‚Äôre using UpscaleLatentBy.\n\nTo adjust the scaling, you can modify the scale_by parameter to set the desired upscaling factor.\n\nSince tiling is not used, the scaling limit is likely around 4x."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 41,
      "type": "Note",
      "pos": [
        2170,
        290
      ],
      "size": [
        540,
        100
      ],
      "flags": {},
      "order": 17,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "For HiresFix, the step count should be about half of the steps used during the initial generation.\n\nWhen adjusting denoise, avoid setting it too high, as it will cause the image to deviate significantly from the original. Keep it at a moderate level for the best results."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 50,
      "type": "Note",
      "pos": [
        -1721.1170654296875,
        -32.63850402832031
      ],
      "size": [
        440.5785217285156,
        286.09918212890625
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "WARNING",
      "properties": {},
      "widgets_values": [
        "Translation of this Workflow made by supercatdoing1456: https://civitai.com/models/892447/illustrious-xls-comfyui-beginner-workflow\n\n(Note added by translator: Currently, as of 3 February 2025, the most recent NoobAI-XL model is the 1.0. Don't know how all these notes written by the original author of this workflow apply to the most recent model.)\n\nNoobAI-XL V-Pred 1.0: https://civitai.com/models/833294?modelVersionId=1190596"
      ],
      "color": "#322",
      "bgcolor": "#533",
      "shape": 2
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        -1220,
        70
      ],
      "size": [
        460,
        100
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            45
          ],
          "slot_index": 0,
          "label": "MODEL"
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            11
          ],
          "slot_index": 1,
          "label": "CLIP"
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            30
          ],
          "slot_index": 2,
          "label": "VAE"
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "noobaiXLNAIXL_vPred10Version.safetensors"
      ]
    },
    {
      "id": 21,
      "type": "Note",
      "pos": [
        100,
        535
      ],
      "size": [
        430,
        180
      ],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {
        "text": ""
      },
      "widgets_values": [
        "EmptyLatentImage can be thought of as a blank canvas specifically for the AI.\n\nThe AI uses this empty canvas to draw the image, so you need to prepare it and input it into the KSampler.\n\nAs for the size, 1024x1024 or any larger size is generally fine. \n\n-----------------------Note added by translator-----------------------\n\nFrom the page of the NoobAI XL model, these are the recommended resolutions:\n\nTotal area around 1024x1024. Best to choose from: 768x1344, 832x1216, 896x1152, 1024x1024, 1152x896, 1216x832, 1344x768\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        930,
        110
      ],
      "size": [
        315,
        474
      ],
      "flags": {},
      "order": 34,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 22,
          "label": "model"
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4,
          "label": "positive"
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6,
          "label": "negative"
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 28,
          "slot_index": 3,
          "label": "latent_image"
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            7,
            31
          ],
          "slot_index": 0,
          "label": "LATENT"
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        254299647326069,
        "fixed",
        27,
        5,
        "euler_ancestral",
        "normal",
        1
      ]
    },
    {
      "id": 33,
      "type": "VAEDecode",
      "pos": [
        2540,
        70
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 41,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 40,
          "label": "samples"
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 44,
          "label": "vae"
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            42,
            49
          ],
          "slot_index": 0,
          "label": "IMAGE"
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        430,
        30
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 29,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 26,
          "label": "clip"
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            4,
            36
          ],
          "slot_index": 0,
          "label": "CONDITIONING"
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "masterpiece,best quality,\n1girl,hatsune_miku, vocaloid, \nstage light, singing, open mouth, crowd, smile, close-up",
        [
          false,
          true
        ]
      ],
      "color": "#322",
      "bgcolor": "#533"
    }
  ],
  "links": [
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      11,
      4,
      1,
      10,
      1,
      "CLIP"
    ],
    [
      16,
      8,
      0,
      12,
      0,
      "IMAGE"
    ],
    [
      17,
      11,
      0,
      13,
      0,
      "*"
    ],
    [
      18,
      13,
      0,
      8,
      1,
      "VAE"
    ],
    [
      21,
      24,
      0,
      25,
      0,
      "*"
    ],
    [
      22,
      25,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      23,
      10,
      0,
      27,
      0,
      "MODEL"
    ],
    [
      24,
      10,
      1,
      27,
      1,
      "CLIP"
    ],
    [
      25,
      27,
      0,
      24,
      0,
      "*"
    ],
    [
      26,
      27,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      27,
      27,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      28,
      14,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      30,
      4,
      2,
      11,
      0,
      "*"
    ],
    [
      31,
      3,
      0,
      31,
      0,
      "LATENT"
    ],
    [
      32,
      31,
      0,
      32,
      3,
      "LATENT"
    ],
    [
      34,
      25,
      0,
      36,
      0,
      "*"
    ],
    [
      35,
      36,
      0,
      32,
      0,
      "MODEL"
    ],
    [
      36,
      6,
      0,
      37,
      0,
      "*"
    ],
    [
      37,
      7,
      0,
      38,
      0,
      "*"
    ],
    [
      38,
      37,
      0,
      32,
      1,
      "CONDITIONING"
    ],
    [
      39,
      38,
      0,
      32,
      2,
      "CONDITIONING"
    ],
    [
      40,
      32,
      0,
      33,
      0,
      "LATENT"
    ],
    [
      42,
      33,
      0,
      35,
      0,
      "IMAGE"
    ],
    [
      43,
      13,
      0,
      43,
      0,
      "*"
    ],
    [
      44,
      43,
      0,
      33,
      1,
      "VAE"
    ],
    [
      45,
      4,
      0,
      46,
      0,
      "MODEL"
    ],
    [
      46,
      46,
      0,
      47,
      0,
      "MODEL"
    ],
    [
      47,
      47,
      0,
      10,
      0,
      "MODEL"
    ],
    [
      48,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      49,
      33,
      0,
      39,
      0,
      "IMAGE"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Use vPred Model",
      "bounding": [
        -730,
        -80,
        480,
        190
      ],
      "color": "#A88",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "HiresFix",
      "bounding": [
        1790,
        -180,
        1492,
        953
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 1.1,
      "offset": {
        "0": -1810.602294921875,
        "1": 28.69491958618164
      }
    },
    "workspace_info": {
      "id": "3JQ-xSYB-WX3Hr4iO2HEG",
      "saveLock": false,
      "cloudID": null,
      "coverMediaPath": null
    },
    "node_versions": {
      "comfy-core": "0.3.13"
    },
    "ue_links": []
  },
  "version": 0.4
}